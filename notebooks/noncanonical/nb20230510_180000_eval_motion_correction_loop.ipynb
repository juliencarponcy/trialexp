{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I weant to test a few ideas about motion correciton on different animals and somehow evaluate the effects and determine which one to adopt.\n",
    "\n",
    "- Methods\n",
    "    1. Old method: lowpass filtering > linear regression > subtraction > dF/F > zscore\n",
    "    2. bandpass filtering to flatten data >  linear regression > subtraction > dF/F > zscore\n",
    "    3. bandpass filtering to flatten data >  PLS  regression > subtraction > dF/F > zscore\n",
    "    4 ????\n",
    "\n",
    "- Evalutation methods\n",
    "    1. Eyeballing the overlaid two curves (signal and estimated motion artefacts)\n",
    "    2. Scatter plot\n",
    "    3. Correlation coefficient\n",
    "    4. cross-correlation and peak at T = 0\n",
    "    5. Sum of absolute difference per unit time???\n",
    "    6. VAR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n",
      "[NbConvertApp] Converting notebook d:\\OneDrive - Nexus365\\Private_Dropbox\\Projects\\trialexp\\notebooks\\noncanonical\\nb20230510_180000_eval_motion_correction_loop.ipynb to python\n",
      "[NbConvertApp] Writing 26817 bytes to d:\\OneDrive - Nexus365\\Private_Dropbox\\Projects\\trialexp\\notebooks\\noncanonical\\nb20230510_180000_eval_motion_correction_loop.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "nb_name = \"nb20230510_180000_eval_motion_correction_loop.ipynb\" #TODO change this\n",
    "\n",
    "basename, ext = os.path.splitext(nb_name)\n",
    "input_path = os.path.join(os.getcwd(), nb_name)\n",
    "\n",
    "!jupyter nbconvert \"{input_path}\" --to=\"python\" --output=\"{basename}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Specify target sessions\n",
    "\n",
    "debug_folders: list of folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_by_sessions = r\"\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\"\n",
    "\n",
    "def join_task_session(taskname, sessionnames: list):\n",
    "    return [os.path.join(dir_by_sessions, taskname, ssn) for ssn in sessionnames]\n",
    "\n",
    "task1 = join_task_session('reaching_go_spout_bar_nov22', [\n",
    "    'kms058-2023-03-24-151254',\n",
    "    'kms058-2023-03-25-184034',\n",
    "    'kms062-2023-02-21-103400',\n",
    "    'kms062-2023-02-22-150828',\n",
    "    'kms063-2023-04-09-183115',\n",
    "    'kms063-2023-04-10-194331',\n",
    "    'kms064-2023-02-13-104949',\n",
    "    'kms064-2023-02-15-104438',\n",
    "    'kms064-2023-02-16-103424',\n",
    "    'RE602-2023-03-22-121414'])\n",
    "\n",
    "task2 = join_task_session('reaching_go_spout_bar_dual_dec22', [\n",
    "    'JC316L-2022-12-07-163252',\n",
    "    'JC316L-2022-12-08-143046'])\n",
    "\n",
    "\n",
    "debug_folders = task1 + task2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\kms058-2023-03-24-151254\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\kms058-2023-03-25-184034\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\kms062-2023-02-21-103400\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\kms062-2023-02-22-150828\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\kms063-2023-04-09-183115\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\kms063-2023-04-10-194331\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\kms064-2023-02-13-104949\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\kms064-2023-02-15-104438\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\kms064-2023-02-16-103424\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_nov22\\RE602-2023-03-22-121414\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_dual_dec22\\JC316L-2022-12-07-163252\n",
      "\\\\ettin\\Magill_lab\\Julien\\Data\\head-fixed\\by_sessions\\reaching_go_spout_bar_dual_dec22\\JC316L-2022-12-08-143046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(d) for d in debug_folders]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trialexp.process.pycontrol.utils import export_session\n",
    "from snakehelper.SnakeIOHelper import getSnake\n",
    "\n",
    "# from workflow.scripts import settings\n",
    "from re import match\n",
    "from pathlib import Path\n",
    "from trialexp.process.pyphotometry.utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.image as mpimg\n",
    "import img2pdf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "class sinput_class():\n",
    "    def __init__(self):\n",
    "        # mock class to mimic the output of getSnake()\n",
    "        self.photometry_folder = None\n",
    "        self.pycontrol_dataframe = None\n",
    "        self.pycontrol_folder = None\n",
    "\n",
    "def load_and_prep_photom(debug_folder):\n",
    "    # (sinput, soutput) = getSnake(locals(), 'workflow/pycontrol.smk',\n",
    "    #                             os.path.join(debug_folder, '/processed/spike2.smrx'),\n",
    "    #                             'export_spike2')\n",
    "    sinput = sinput_class()\n",
    "    sinput.photometry_folder = os.path.join(debug_folder,'pyphotometry')\n",
    "    sinput.pycontrol_dataframe = os.path.join(debug_folder,'processed','df_pycontrol.pkl')\n",
    "    sinput.pycontrol_folder = os.path.join(debug_folder,'pycontrol')\n",
    "\n",
    "    # %% Photometry dict\n",
    "\n",
    "    # fn = glob(sinput.photometry_folder+'\\*.ppd')[0]\n",
    "    fn = list(Path(sinput.photometry_folder).glob('*.ppd'))\n",
    "    if fn == []:\n",
    "        data_photometry = None\n",
    "    else:\n",
    "        fn = fn[0]\n",
    "        data_photometry = import_ppd(fn)\n",
    "\n",
    "        data_photometry = denoise_filter(data_photometry)\n",
    "        data_photometry = motion_correction(data_photometry)\n",
    "        data_photometry = compute_df_over_f(data_photometry, low_pass_cutoff=0.001)\n",
    "\n",
    "\n",
    "    # no down-sampling here\n",
    "\n",
    "    # %% Load data\n",
    "    df_pycontrol = pd.read_pickle(sinput.pycontrol_dataframe)\n",
    "\n",
    "    pycontrol_time = df_pycontrol[df_pycontrol.name == 'rsync'].time\n",
    "\n",
    "    # assuming just one txt file\n",
    "    pycontrol_txt = list(Path(sinput.pycontrol_folder).glob('*.txt'))\n",
    "\n",
    "    with open(pycontrol_txt[0], 'r') as f:\n",
    "        all_lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    count = 0\n",
    "    print_lines = []\n",
    "    while count < len(all_lines):\n",
    "        # all_lines[count][0] == 'P'\n",
    "        if bool(match('P\\s\\d+\\s', all_lines[count])):\n",
    "            print_lines.append(all_lines[count][2:])\n",
    "            count += 1\n",
    "            while (count < len(all_lines)) and not (bool(match('[PVD]\\s\\d+\\s', all_lines[count]))):\n",
    "                print_lines[-1] = print_lines[-1] + \\\n",
    "                    \"\\n\" + all_lines[count]\n",
    "                count += 1\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "    v_lines = [line[2:] for line in all_lines if line[0] == 'V']\n",
    "\n",
    "\n",
    "    # %%\n",
    "    if fn == []:\n",
    "        photometry_times_pyc = None\n",
    "    else:\n",
    "        photometry_aligner = Rsync_aligner(\n",
    "            pycontrol_time, data_photometry['pulse_times_2'])\n",
    "        photometry_times_pyc = photometry_aligner.B_to_A(data_photometry['time'])\n",
    "\n",
    "    # remove all state change event\n",
    "    df_pycontrol = df_pycontrol.dropna(subset='name')\n",
    "    df2plot = df_pycontrol[df_pycontrol.type == 'event']\n",
    "    # state is handled separately with export_state, whereas parameters are handled vchange_to_text\n",
    "\n",
    "    keys = df2plot.name.unique()\n",
    "\n",
    "    photometry_keys = ['analog_1', 'analog_2',  'analog_1_filt', 'analog_2_filt',\n",
    "                    'analog_1_est_motion', 'analog_1_corrected', 'analog_1_baseline_fluo',\n",
    "                    'analog_1_df_over_f']\n",
    "\n",
    "    return df_pycontrol, pycontrol_time, data_photometry, photometry_times_pyc, photometry_keys\n",
    "\n",
    "# export_session(df_pycontrol, keys, \n",
    "#     data_photometry = data_photometry,\n",
    "#     photometry_times_pyc = photometry_times_pyc,\n",
    "#     photometry_keys = photometry_keys,\n",
    "#     print_lines = print_lines,\n",
    "#     v_lines = v_lines,\n",
    "#     smrx_filename=soutput.spike2_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for d in debug_folders:\n",
    "    data_dict = dict(df_pycontrol=None, pycontrol_time=None, data_photometry=None, photometry_times_pyc=None, photometry_keys = None, debug_folder=None)\n",
    "    data_dict['df_pycontrol'], data_dict['pycontrol_time'], data_dict['data_photometry'], \\\n",
    "        data_dict['photometry_times_pyc'], data_dict['photometry_keys'] = load_and_prep_photom(d)\n",
    "    data_dict['debug_folder'] = d\n",
    "    data_dict['session_ID'] = os.path.basename(d)\n",
    "\n",
    "    data_list.append(data_dict)\n",
    "df_data = pd.DataFrame(data_list)\n",
    "\n",
    "df_data['subject_ID'] = [r['subject_ID'] if r is not None else None for r in df_data['data_photometry']]\n",
    "df_data['date_time'] = [r['date_time']\n",
    "                        if r is not None else None for r in df_data['data_photometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     kms058-2023-03-24-151254\n",
       "1     kms058-2023-03-25-184034\n",
       "2     kms062-2023-02-21-103400\n",
       "3     kms062-2023-02-22-150828\n",
       "4     kms063-2023-04-09-183115\n",
       "5     kms063-2023-04-10-194331\n",
       "6     kms064-2023-02-13-104949\n",
       "7     kms064-2023-02-15-104438\n",
       "8     kms064-2023-02-16-103424\n",
       "9      RE602-2023-03-22-121414\n",
       "10    JC316L-2022-12-07-163252\n",
       "11    JC316L-2022-12-08-143046\n",
       "Name: session_ID, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['session_ID']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing and evaluation\n",
    "\n",
    "cf. \n",
    "\n",
    "```\n",
    "process/pyphotometry/utils.py/motion_corretion()\n",
    "```\n",
    "\n",
    "- Correlation Coefficients and scatter plots\n",
    "- Cross-correlation and measuring the peak at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['df_pycontrol', 'pycontrol_time', 'data_photometry',\n",
       "       'photometry_times_pyc', 'photometry_keys', 'debug_folder', 'session_ID',\n",
       "       'subject_ID', 'date_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     kms058\n",
       "1     kms058\n",
       "2     kms062\n",
       "3     kms062\n",
       "4     kms063\n",
       "5     kms063\n",
       "6     kms064\n",
       "7     kms064\n",
       "8     kms064\n",
       "9      RE602\n",
       "10      None\n",
       "11      None\n",
       "Name: subject_ID, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['subject_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'name', 'time', 'duration', 'value'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.iloc[0, 0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_indices = np.argwhere(np.isnan(photometry_times_pyc))\n",
    "# T_nonan = np.delete(photometry_times_pyc, nan_indices)\n",
    "# max_time_ms = T_nonan[-1]\n",
    "\n",
    "\n",
    "def get_newTandY_orig(T, photometry_dict, name, max_time_ms, photometry_times_pyc):\n",
    "    nan_indices = np.argwhere(np.isnan(photometry_times_pyc))\n",
    "    T_nonan = np.delete(photometry_times_pyc, nan_indices)\n",
    "    max_time_ms = T_nonan[-1]\n",
    "\n",
    "\n",
    "    T = photometry_times_pyc  # not down-sampled yet\n",
    "\n",
    "    nan_indices = np.argwhere(np.isnan(T))\n",
    "    T_nonan = np.delete(T, nan_indices)\n",
    "\n",
    "    Y = photometry_dict[name]\n",
    "    Y_nonan = np.delete(Y, nan_indices)  # []\n",
    "    max_time_ms = T_nonan[-1]\n",
    "\n",
    "    # NOTE sampling_rate was originally 1000\n",
    "    new_T = np.arange(0, max_time_ms, 1/1000*1000)\n",
    "    new_Y = np.interp(new_T, T_nonan, Y_nonan)\n",
    "    return new_T, new_Y\n",
    "\n",
    "\n",
    "def get_newTandY_down(T, photometry_dict, name, max_time_ms, photometry_times_pyc):\n",
    "    nan_indices = np.argwhere(np.isnan(photometry_times_pyc))\n",
    "    T_nonan = np.delete(photometry_times_pyc, nan_indices)\n",
    "    max_time_ms = T_nonan[-1]\n",
    "\n",
    "    Tdown = [T[i] for i in range(0, len(T), 10)]  # down sampled time vector\n",
    "\n",
    "    nan_indices = np.argwhere(np.isnan(Tdown))\n",
    "    Tdown_nonan = np.delete(Tdown, nan_indices)\n",
    "\n",
    "    Y = photometry_dict[name]\n",
    "    Y_nonan = np.delete(Y, nan_indices)  # []\n",
    "\n",
    "    # Need to use interp to accomodate data into Spike2 bins\n",
    "    # NOTE sampling_rate is already downsampled by 10\n",
    "    new_T = np.arange(0, max_time_ms, 1/photometry_dict['sampling_rate']*1000)\n",
    "    new_Y = np.interp(new_T, Tdown_nonan, Y_nonan)\n",
    "    return new_T, new_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analog_1\n",
      "analog_2\n",
      "digital_1\n",
      "digital_2\n",
      "pulse_inds_1\n",
      "pulse_inds_2\n",
      "pulse_times_1\n",
      "pulse_times_2\n",
      "time\n",
      "subject_ID\n",
      "date_time\n",
      "mode\n",
      "sampling_rate\n",
      "volts_per_division\n",
      "LED_current\n",
      "version\n",
      "analog_1_filt\n",
      "analog_2_filt\n",
      "analog_1_est_motion\n",
      "analog_1_corrected\n",
      "motion_corrected\n",
      "analog_1_baseline_fluo\n",
      "analog_1_df_over_f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[print(k) for k in df_data.loc[0,'data_photometry'].keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowpass_freq = 20\n",
    "highpass_freq = 0.001  # 1000 s cycle\n",
    "sampling_rate = 1000 #TODO assuming \n",
    "\n",
    "# trialexp\\process\\pyphotometry\\utils.py\n",
    "# see https://vscode.dev/github/juliencarponcy/trialexp/blob/fd1e0dcc857275cafa7f809a104fd60e73ce1458/trialexp/process/pyphotometry/utils.py#L51\n",
    "b, a = get_filt_coefs(low_pass=lowpass_freq,\n",
    "                      high_pass=highpass_freq,\n",
    "                      sampling_rate=sampling_rate)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "GTP-4\n",
    "\n",
    "> In the context of digital filters, the roots of the polynomial represented by the filter coefficients are very important, because they determine the behavior of the filter. Specifically, the roots of the 'a' coefficients (which form the denominator of the filter's transfer function) are called the \"**poles**\" of the filter. The locations of these poles in the complex plane determine whether the filter is stable or not.\n",
    "\n",
    "> If all poles are inside the unit circle (meaning their absolute value is less than 1), then the filter is stable. If any pole is outside the unit circle, then the filter is unstable. This is why we use `numpy.roots(a)` and `numpy.abs()` to check the stability of the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_stability(b, a):\n",
    "    \"\"\"Check the stability of a digital filter.\"\"\"\n",
    "    # Get the poles of the filter\n",
    "    poles = np.roots(a)\n",
    "\n",
    "    # Check if all poles are inside the unit circle\n",
    "    return np.all(np.abs(poles) < 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_lowpass(i,j, ax ):\n",
    "    # i = 0\n",
    "    # j = 0\n",
    "    plt.sca(ax[i, j])\n",
    "\n",
    "    plt.plot(analog_2_filt, analog_1_filt, '+', color=(0.5,0.5,0.5), markersize=2, zorder=1)\n",
    "\n",
    "    # Calculate the 2D histogram\n",
    "    hist, x_edges, y_edges = np.histogram2d(analog_2_filt, analog_1_filt, bins=30)\n",
    "\n",
    "    # Calculate the bin centers from the bin edges\n",
    "    x_centers = (x_edges[:-1] + x_edges[1:]) / 2\n",
    "    y_centers = (y_edges[:-1] + y_edges[1:]) / 2\n",
    "\n",
    "    # Create a meshgrid of bin centers\n",
    "    X, Y = np.meshgrid(x_centers, y_centers)\n",
    "\n",
    "    # Create the custom colormap\n",
    "\n",
    "    log_norm = mcolors.LogNorm(vmin=1e-10, vmax=None)\n",
    "\n",
    "    # Plot the contour plot\n",
    "    #plt.contourf(X, Y, hist.T, cmap=custom_cmap, norm=norm)\n",
    "    cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
    "\n",
    "\n",
    "    plt.xlabel('analog_2_filt, red')\n",
    "    plt.ylabel('analog_1_filt, green')\n",
    "\n",
    "    plt.colorbar(cnt, location='top')\n",
    "\n",
    "    plt.title('Lowpass filtering only', y = 1.25)\n",
    "\n",
    "    # linregress\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(\n",
    "        x=analog_2_filt, y=analog_1_filt)\n",
    "\n",
    "    x0 = np.arange(np.min(analog_2_filt), np.max(analog_2_filt), \n",
    "                (np.max(analog_2_filt) - np.min(analog_2_filt))/1000)\n",
    "    y0 = slope*x0 + intercept\n",
    "\n",
    "    plt.plot(x0, y0, '-', color='red', linewidth=2, zorder=3)\n",
    "\n",
    "    plt.text(0.5,0.9,f'$R^2=${r_value**2:.3f}', transform=plt.gca().transAxes, ha='left')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLS result is virtually identical to linear regression.\n",
    "\n",
    "Not worth!\n",
    "\n",
    "GTP-4\n",
    "\n",
    "> If you ran `linregress()` and `PLSRegression(n_components=1)` on the same dataset and obtained virtually identical results, it suggests that a linear relationship between the predictor variables and the response variable is sufficient to explain the variation in the data, and that the relationship is not highly nonlinear or complex.\n",
    "\n",
    "> `linregress()` performs a simple linear regression analysis that fits a straight line to the data, while `PLSRegression(n_components=1)` performs a partial least squares regression analysis that projects the data onto a lower-dimensional space to capture the linear relationship between the variables.\n",
    "\n",
    "> When `n_components=1` is used in `PLSRegression()`, the model will use only one latent variable to model the relationship between the predictor variables and the response variable. This means that the model will have a low level of complexity and may underfit the data if the relationship between the variables is more complex. However, if the data exhibits a linear relationship, then using only one latent variable can be a good starting point to explore the relationship between the variables and identify the most important features.\n",
    "\n",
    ">L In summary, if `linregress()` and `PLSRegression(n_components=1)` yield similar results, it suggests that a linear relationship between the predictor variables and the response variable is sufficient to explain the variation in the data. However, it is always a good idea to check the assumptions of the regression models and to evaluate the performance of the models using appropriate metrics such as R-squared, mean squared error, etc., before drawing conclusions about the relationship between the variables. Additionally, you may want to experiment with different values of `n_components` in `PLSRegression()` to find the optimal level of complexity for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_bandpass(i, j, ax):\n",
    "\n",
    "    plt.sca(ax[i, j])\n",
    "\n",
    "    plt.plot(analog_2_bp, analog_1_bp, '+', color=(0.5,0.5,0.5),markersize=2, zorder=1)\n",
    "\n",
    "    # Calculate the 2D histogram\n",
    "    hist, x_edges, y_edges = np.histogram2d(analog_2_bp, analog_1_bp, bins=30)\n",
    "\n",
    "    # Calculate the bin centers from the bin edges\n",
    "    x_centers = (x_edges[:-1] + x_edges[1:]) / 2\n",
    "    y_centers = (y_edges[:-1] + y_edges[1:]) / 2\n",
    "\n",
    "    # Create a meshgrid of bin centers\n",
    "    X, Y = np.meshgrid(x_centers, y_centers)\n",
    "\n",
    "    # Create the custom colormap\n",
    "\n",
    "    log_norm = mcolors.LogNorm(vmin=1e-10, vmax=None)\n",
    "\n",
    "    # Plot the contour plot\n",
    "    #plt.contourf(X, Y, hist.T, cmap=custom_cmap, norm=norm)\n",
    "    cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
    "\n",
    "\n",
    "    df_data.loc[0,'data_photometry']['analog_1']\n",
    "    plt.xlabel('analog_2_bp, red')\n",
    "    plt.ylabel('analog_1_bp, green')\n",
    "\n",
    "    cb1= plt.colorbar(cnt, location='top')\n",
    "\n",
    "    ax[i,j].set_title('Bandpass filtering', y = 1.25)\n",
    "\n",
    "    # linregress\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(\n",
    "        x=analog_2_bp, y=analog_1_bp)\n",
    "\n",
    "    x0 = np.arange(np.min(analog_2_bp), np.max(analog_2_bp), \n",
    "                (np.max(analog_2_bp) - np.min(analog_2_bp))/1000)\n",
    "    y0 = slope*x0 + intercept\n",
    "\n",
    "    plt.plot(x0, y0, '-', color='red', linewidth=2, zorder=3)\n",
    "\n",
    "    analog_1_est_motion_bp = slope * analog_2_bp + intercept\n",
    "\n",
    "    plt.text(0.5, 0.9, f'$R^2$={r_value**2:.2f}',\n",
    "            transform=plt.gca().transAxes, ha='left')\n",
    "    \n",
    "\n",
    "    # PLS reqression\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        analog_2_bp.reshape(-1, 1), analog_1_bp.reshape(-1, 1), test_size=0.2, random_state=42)\n",
    "\n",
    "    # PLS regression model creation and learning\n",
    "    pls = PLSRegression(n_components=1)\n",
    "    pls.fit(X_train, y_train)\n",
    "\n",
    "    # model prediction and evaluation\n",
    "    y_pred = pls.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    plt.text(0.5,0.84,f'PLS $R^2=${r2:.2f}', transform=plt.gca().transAxes, ha='left')\n",
    "    plt.text(0.5,0.78,f'PLS $MSE$={mse:.2f}', transform=plt.gca().transAxes, ha='left')\n",
    "\n",
    "    plt.plot(X_test, y_pred, ':', color='yellow', linewidth=2)\n",
    "\n",
    "\n",
    "    return analog_1_est_motion_bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_waveform_average(signal, window_before_ms, window_after_ms, trig_ind):\n",
    "\n",
    "    # Example time series data and events\n",
    "    # signal = analog_1_bp\n",
    "\n",
    "    # Define the window around events to compute the average waveform\n",
    "    # window_before_ms = 1000 * 3\n",
    "    # window_after_ms = 1000 * 3\n",
    "\n",
    "    # Initialize an empty array to store the waveform segments\n",
    "    waveform_segments = []\n",
    "\n",
    "    # Extract waveform segments around each event index\n",
    "    for event_index in trig_ind:\n",
    "        start_index = event_index - window_before_ms\n",
    "        end_index = event_index + window_after_ms + 1\n",
    "        segment = signal[start_index:end_index]\n",
    "        waveform_segments.append(segment)\n",
    "\n",
    "    # Stack the waveform segments and compute the average along the first axis\n",
    "    waveform_segments = np.stack(waveform_segments)\n",
    "    waveform_average = np.mean(waveform_segments, axis=0)\n",
    "    waveform_std = np.std(waveform_segments, axis=0)\n",
    "    waveform_sem = waveform_std / np.sqrt(waveform_segments.shape[0])\n",
    "    sample_size = waveform_segments.shape[0]\n",
    "    # print(\"Waveform average:\", waveform_average)\n",
    "\n",
    "    return waveform_segments, waveform_average, waveform_std, waveform_sem, sample_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform_average(i, j, ax, ylim: list = None):\n",
    "    # ylim = [-0.015, 0.015]\n",
    "\n",
    "    plt.sca(ax[i, j])\n",
    "\n",
    "    plt.cla()\n",
    "\n",
    "    plt.plot(T_vec, wa_analog_1_bp['waveform_average'], label='analog_1_bp', color='#2ca02c', ls = '-')\n",
    "    plt.plot(T_vec, wa_analog_1_est_motion['waveform_average'], label='analog_1_est_motion', color='#2ca02c', ls='--')\n",
    "    plt.plot(T_vec, wa_analog_1_corrected['waveform_average'], label='analog_1_corrected', color='#2ca02c', ls='-.')\n",
    "\n",
    "    plt.plot(T_vec, wa_analog_2_bp['waveform_average'], label='analog_2_bp', color='#d62728', ls = '-')\n",
    "\n",
    "    plt.plot(T_vec, wa_analog_1_est_motion_bp['waveform_average'],\n",
    "            label='analog_1_est_motion_bp', color='#bcbd22', ls='--')\n",
    "    plt.plot(T_vec, wa_analog_1_corrected_bp['waveform_average'],\n",
    "            label='analog_1_corrected_bp', color='#bcbd22', ls='-.')\n",
    "\n",
    "\n",
    "    plt.xlabel('Time relative to `analog_2_bp`\\n exceeding $\\pm$ 2SD after >3 s interval (s)')\n",
    "    plt.ylabel('Fluorescence (V)')\n",
    "\n",
    "    plt.gca().legend(loc='upper left', frameon=False)\n",
    "\n",
    "    plt.text(0.75, 0.03, f\"n = {wa_analog_1_bp['sample_size']:d} events\", transform=plt.gca().transAxes)\n",
    "\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "\n",
    "    plt.gca().legend(loc='upper left', frameon=False, fontsize=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overview(i, j, ax):\n",
    "\n",
    "    plt.sca(ax[i,j])\n",
    "    plt.cla()\n",
    "\n",
    "    plt.plot([t/1000 for t in trig_ms], [0 for _ in range(len(trig_ms))],'.')\n",
    "    plt.plot([t/1000 for t in photometry_times_pyc], [v - mn for v in analog_1_filt],'-', label='analog_1_filt', color='#2ca02c', linewidth=0.75)\n",
    "    plt.plot([t/1000 for t in photometry_times_pyc], [v - mn for v in analog_2_filt],'-', label='analog_2_filt', color='#d62728',linewidth=0.75)\n",
    "    plt.plot([t/1000 for t in photometry_times_pyc], [v - mn for v in analog_1_bp],'--', label='analog_1_bp', color='#2ca02c',linewidth=0.75, alpha=0.5)\n",
    "    plt.plot([t/1000 for t in photometry_times_pyc], [v - mn for v in analog_2_bp],'--', label='analog_2_bp', color='#d62728',linewidth=0.75, alpha=0.5)\n",
    "\n",
    "    plt.xlim(np.nanmin(photometry_times_pyc)/1000, np.nanmax(photometry_times_pyc)/1000)\n",
    "    plt.legend(loc='upper right', frameon=False, fontsize=7)\n",
    "    plt.ylabel('Fluorescence (V)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title('The whole session view')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxes(i, j,  ax):\n",
    "    data = [analog_1_filt, analog_1_est_motion, analog_1_corrected, analog_2_filt,\n",
    "            analog_1_bp, analog_1_est_motion_bp, analog_1_corrected_bp, analog_2_bp]\n",
    "\n",
    "    plt.sca(ax[i, j])\n",
    "\n",
    "    bx = plt.boxplot(data, showfliers=False)  # too many outliers\n",
    "\n",
    "    for i in range(0, 8):\n",
    "        plt.plot(i+1, np.nanmax(data[i]), 'o',\n",
    "                markerfacecolor='none', color=[0.5, 0.5, 0.5])\n",
    "        plt.plot(i+1, np.nanmin(data[i]), 'o',\n",
    "                markerfacecolor='none', color=[0.5, 0.5, 0.5])\n",
    "\n",
    "    plt.xticks([1, 2, 3, 4, 5, 6, 7, 8], ['analog_1_filt', 'analog_1_est_motion', 'analog_1_corrected',  'analog_2_filt',\n",
    "                                        'analog_1_bp', 'analog_1_est_motion_bp', 'analog_1_corrected_bp', 'analog_2_bp'])\n",
    "    plt.xticks(rotation=60, ha='right')\n",
    "\n",
    "    # [L.set_alpha(0.2) for L in bx['fliers']]\n",
    "    plt.ylabel('Fluorescence (V)')\n",
    "    plt.title('Data distributions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_n_events(top_n: int, mn: float, sd: float, interval_ms: float):\n",
    "\n",
    "    for thre in np.linspace(2, 0.5, 16):\n",
    "        ind = np.where(np.abs(analog_2_bp - mn) > thre * sd)[0]\n",
    "        diffs = np.diff(ind)\n",
    "        non_consecutive_positions = np.where(diffs != 1)[0]\n",
    "\n",
    "        preceded_by_interval = positions = np.where(diffs > interval_ms)[0]\n",
    "        # preceded by 3 s intervals was too much\n",
    "\n",
    "\n",
    "        ind_ = np.array(sorted(list(set(non_consecutive_positions) & set(preceded_by_interval))))\n",
    "\n",
    "        if len(ind_) == 0:# failed to find an event\n",
    "            continue\n",
    "\n",
    "        trig_ind = ind[ind_ + 1]\n",
    "\n",
    "        trig_ms = photometry_times_pyc[trig_ind]\n",
    "\n",
    "        if len(trig_ms) >= top_n:\n",
    "            break\n",
    "\n",
    "    \n",
    "    if len(trig_ms) < top_n:\n",
    "        # failed to find top_n events satisfying the condition\n",
    "        print(f'failed to find {top_n:d} events satisfying the condition; only {len(trig_ms):d} found')\n",
    "\n",
    "    return trig_ind, trig_ms\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "  8%|▊         | 1/12 [00:29<05:22, 29.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      " 17%|█▋        | 2/12 [01:07<05:47, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to find 30 events satisfying the condition; only 15 found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [01:37<04:53, 32.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      " 33%|███▎      | 4/12 [02:07<04:11, 31.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      " 42%|████▏     | 5/12 [02:35<03:30, 30.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      " 50%|█████     | 6/12 [03:03<02:57, 29.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      " 58%|█████▊    | 7/12 [03:23<02:11, 26.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      " 67%|██████▋   | 8/12 [03:55<01:52, 28.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      " 75%|███████▌  | 9/12 [04:36<01:37, 32.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is stable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\4234656188.py:24: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "C:\\Users\\phar0528\\AppData\\Local\\Temp\\ipykernel_50080\\3906506082.py:23: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  cnt = plt.contourf(X, Y, hist.T, cmap='viridis', norm=log_norm, zorder=2)\n",
      "100%|██████████| 12/12 [05:10<00:00, 25.88s/it]\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['xtick.direction'] = 'out'\n",
    "plt.rcParams['ytick.direction'] = 'out'\n",
    "plt.rcParams['font.family'] = ['Arial']\n",
    "\n",
    "\n",
    "plt.close()\n",
    "plt.interactive(True) #TODO not sure\n",
    "\n",
    "cm = 1/2.54  # centimeters in inches\n",
    "A4_portrait = (21*cm, 29.7*cm)\n",
    "\n",
    "\n",
    "for r in tqdm(range(0, df_data.shape[0])):\n",
    "    fig, ax = plt.subplots(3,2, figsize=A4_portrait)\n",
    "\n",
    "    if df_data.loc[r,'subject_ID'] is  None:\n",
    "        fig.suptitle(df_data.loc[r, 'subject_ID'])\n",
    "\n",
    "        fig.savefig(f\"temp{r:02d}.png\", dpi=400) # save temp bitmap figure\n",
    "        \n",
    "        # Close the figure\n",
    "        plt.close(fig)\n",
    "        continue\n",
    "\n",
    "    analog_1_filt = df_data.loc[r,'data_photometry']['analog_1']\n",
    "    analog_2_filt = df_data.loc[r,'data_photometry']['analog_2']\n",
    "\n",
    "    analog_1_est_motion = df_data.loc[r,'data_photometry']['analog_1_est_motion']\n",
    "    analog_1_corrected = df_data.loc[r,'data_photometry']['analog_1_corrected']\n",
    "    analog_1_df_over_f = df_data.loc[r, 'data_photometry']['analog_1_est_motion']\n",
    "\n",
    "    #do_analysis(df_data, r)\n",
    "\n",
    "    analog_1_bp = filtfilt(b, a, df_data.loc[r,'data_photometry']['analog_1'], padtype='even')\n",
    "    analog_2_bp = filtfilt(b, a, df_data.loc[r,'data_photometry']['analog_2'], padtype='even')\n",
    "\n",
    "    is_stable = check_stability(b, a)\n",
    "    print(f\"The filter is {'stable' if is_stable else 'unstable'}.\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.5)\n",
    "\n",
    "    plot_scatter_lowpass(0, 0, ax )\n",
    "\n",
    "    analog_1_est_motion_bp = plot_scatter_bandpass(0, 1, ax)\n",
    "\n",
    "\n",
    "    # triggered waveform average analyses\n",
    "    photometry_times_pyc = df_data.loc[r, 'photometry_times_pyc']\n",
    "\n",
    "    mn = np.mean(analog_2_bp)\n",
    "    sd = np.std(analog_2_bp)\n",
    "\n",
    "    trig_ind, trig_ms = find_top_n_events(30, mn, sd, 1000)\n",
    "    # ind = np.where(np.abs(analog_2_bp - mn) > 1 * sd)[0]\n",
    "    # diffs = np.diff(ind)\n",
    "    # non_consecutive_positions = np.where(diffs != 1)[0]\n",
    "\n",
    "    # preceded_by_interval = positions = np.where(diffs > 300)[0]\n",
    "    # # preceded by 3 s intervals was too much\n",
    "\n",
    "\n",
    "    # ind_ = np.array(sorted(list(set(non_consecutive_positions) & set(preceded_by_interval))))\n",
    "\n",
    "    # trig_ind = ind[ind_ + 1]\n",
    "\n",
    "    # trig_ms = photometry_times_pyc[trig_ind]\n",
    "\n",
    "\n",
    "    window_before_ms = 1000 * 3\n",
    "    window_after_ms = 1000 * 4\n",
    "\n",
    "    keys = ['waveform_segments', 'waveform_average', 'waveform_std', 'waveform_sem', 'sample_size']\n",
    "\n",
    "    wa_analog_1_bp = dict(zip(keys, get_waveform_average(analog_1_bp, window_before_ms, window_after_ms, trig_ind)))\n",
    "    wa_analog_2_bp = dict(zip(keys, get_waveform_average(analog_2_bp, window_before_ms, window_after_ms, trig_ind)))\n",
    "\n",
    "    wa_analog_1_est_motion = dict(zip(keys, get_waveform_average(analog_1_est_motion, window_before_ms, window_after_ms, trig_ind)))\n",
    "    wa_analog_1_corrected = dict(zip(keys, get_waveform_average(analog_1_corrected, window_before_ms, window_after_ms, trig_ind)))\n",
    "\n",
    "    wa_analog_1_est_motion_bp = dict(zip(keys, get_waveform_average(analog_1_est_motion_bp, window_before_ms, window_after_ms, trig_ind)))\n",
    "\n",
    "    analog_1_corrected_bp = analog_1_bp - analog_1_est_motion_bp #TODO is this correct\n",
    "\n",
    "    wa_analog_1_corrected_bp = dict(zip(keys, get_waveform_average(analog_1_corrected_bp, window_before_ms, window_after_ms, trig_ind)))\n",
    "\n",
    "    T_vec = np.linspace(-1 * window_before_ms , window_after_ms, len(wa_analog_1_bp['waveform_average']))/1000\n",
    "\n",
    "    plot_waveform_average(1, 0, ax)\n",
    "\n",
    "    plot_waveform_average(1, 1, ax, [-0.015, 0.015])\n",
    "\n",
    "    plot_overview(2, 0, ax)\n",
    "\n",
    "    plot_boxes(2, 1,  ax)\n",
    "\n",
    "    fig.suptitle(df_data.loc[r, 'session_ID'])\n",
    "\n",
    "    fig.savefig(f\"temp{r:02d}.png\", dpi=400) # save temp bitmap figure\n",
    "        \n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "png_files = [f for f in os.listdir('.') if re.search(r'^temp\\d{2}\\.png$', f)]\n",
    "png_files.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n"
     ]
    }
   ],
   "source": [
    "import img2pdf\n",
    "with open(\"nb20230510_180000_eval_motion_correction_loop.pdf\", \"wb\") as f:\n",
    "    f.write(img2pdf.convert(png_files))\n",
    "\n",
    "for r in range(0, df_data.shape[0]):\n",
    "    os.remove(f\"temp{r:02d}.png\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event-triggered waveform average is so far the most informative.\n",
    "\n",
    "- **kms058** It's very clear that the original motion correction is adding more problem than correcting. The new method is much better.\n",
    "- **kms062-2023-02-21** R^2 is 0.94 and we don't see motion artefact in the data. Maybe some problem in recording.\n",
    "- **kms062-2023-02-22** Again, no artefact\n",
    "- **kms063-2023-04-09** Relatively big motion artefact. The new method is slightly better. But it doesn't make a lot of sense\n",
    "- **kms064-2023-02-13** Motion artefact only exist in red channel. \n",
    "- **kms064-2023-02-15** New method is slightly better?\n",
    "- **RE602-2023-03-22** Both are equally bad.\n",
    "\n",
    "Overall, the new method only outperformed for kms058 and in other cases the effect was not clear.\n",
    "It is worth changing the pipeline?\n",
    "\n",
    "What about $\\frac{\\Delta F}{F}$?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`PdfPages` is able to save figures as vector graphics in multi-page PDF, but the file size can be huge when there are too many data points.\n",
    "\n",
    "```python\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with PdfPages('output.pdf') as pdf:\n",
    "    for i in range(5):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(range(10), [j ** (i+1) for j in range(10)])  # example plot\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "```\n",
    "\n",
    "\n",
    "`img2pdf` can convert multiple PNGs into multi-page PDF\n",
    "\n",
    "```python\n",
    "import img2pdf\n",
    "import os\n",
    "\n",
    "# Get all png files in the current directory\n",
    "png_files = [f for f in os.listdir('.') if f.endswith('.png')]\n",
    "\n",
    "# Sort the images by name or modify as required to get them in the order you want\n",
    "png_files.sort()\n",
    "\n",
    "with open(\"output.pdf\", \"wb\") as f:\n",
    "    f.write(img2pdf.convert(png_files))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trialexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
