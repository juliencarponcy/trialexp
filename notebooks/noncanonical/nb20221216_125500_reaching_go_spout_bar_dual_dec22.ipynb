{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reaching_go_spout_bar_dual_dec22\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert \"D:\\OneDrive - Nexus365\\Private_Dropbox\\Projects\\trialexp\\notebooks\\noncanonical\\nb20221216_125500_reaching_go_spout_bar_dual_dec22.ipynb\" --to=\"python\" --output-dir=\"D:\\OneDrive - Nexus365\\Private_Dropbox\\Projects\\trialexp\\notebooks\\noncanonical\" --output=\"nb20221216_125500_reaching_go_spout_bar_dual_dec22\"\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick analysis of instrumental reaching\n",
    "\n",
    "Visualise the ephys sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow for automatic reloading of classes and function when updating the code\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "# Import Session and Experiment class with helper functions\n",
    "from trialexp.process.data_import import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trial_window = [-2000, 6000] # in ms\n",
    "\n",
    "# time limit around trigger to perform an event\n",
    "# determine successful trials\n",
    "timelim = [0, 2000] # in ms\n",
    "\n",
    "# Digital channel nb of the pyphotometry device\n",
    "# on which rsync signal is sent (from pycontrol device)\n",
    "rsync_chan = 2\n",
    "\n",
    "basefolder, _ = os.path.split(os.path.split(os.getcwd())[0])\n",
    "\n",
    "# These must be absolute paths\n",
    "# use this to use within package tasks files (in params)\n",
    "tasksfile = os.path.join(basefolder,'params\\\\tasks_params.csv')\n",
    "# use this to put a local full path\n",
    "#tasksfile = -r'C:/.../tasks_params.csv' \n",
    "\n",
    "# photometry_dir = r'\\\\ettin\\Magill_Lab\\Julien\\Data\\head-fixed\\test_folder\\photometry'\n",
    "photometry_dir = r'\\\\ettin\\Magill_Lab\\Julien\\Data\\head-fixed\\kms_pyphotometry'\n",
    "video_dir = r'\\\\ettin\\Magill_Lab\\Julien\\Data\\head-fixed\\videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = pd.read_csv(tasksfile, usecols=[1, 2, 3, 4], index_col=False)\n",
    "tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_root_dir = 'T:\\\\Data\\\\head-fixed\\\\pyphotometry\\\\data'\n",
    "pycontrol_root_dir = 'T:\\\\Data\\\\head-fixed\\\\pycontrol'\n",
    "\n",
    "root_folders = [photo_root_dir, pycontrol_root_dir]\n",
    "horizontal_folder_pycontrol = 'T:\\\\Data\\\\head-fixed\\\\test_folder\\\\pycontrol'\n",
    "horizontal_folder_photometry = 'T:\\\\Data\\\\head-fixed\\\\test_folder\\\\photometry'\n",
    "\n",
    "copy_files_to_horizontal_folders(\n",
    "    root_folders, horizontal_folder_pycontrol, horizontal_folder_photometry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder of a full experimental batch, all animals included\n",
    "\n",
    "# Enter absolute path like this\n",
    "# pycontrol_files_path = r'T:\\Data\\head-fixed\\test_folder\\pycontrol'\n",
    "\n",
    "# or this if you want to use data from the sample_data folder within the package\n",
    "pycontrol_files_path = os.path.join(basefolder, 'sample_data/pycontrol')\n",
    "pycontrol_files_path = r'T:\\Data\\head-fixed\\kms_pycontrol'\n",
    "\n",
    "# Load all raw text sessions in the indicated folder or a sessions.pkl file\n",
    "# if already existing in folder_path\n",
    "exp_cohort = Experiment(pycontrol_files_path, update = True) #TODO\n",
    "\n",
    "# Only use if the Experiment cohort as been processed by trials before\n",
    "# TODO: assess whether this can be removed or not\n",
    "exp_cohort.by_trial = True\n",
    "\n",
    "\n",
    "smrx_folder_path = r'T:\\Data\\head-fixed\\kms_pycontrol\\smrx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many combinations possible\n",
    "conditions_dict0 = {'trigger': 'hold_for_water', 'valid': True}\n",
    "\n",
    "# Aggregate all condition dictionaries in a list\n",
    "condition_list = [conditions_dict0]\n",
    "# Aliases for conditions\n",
    "cond_aliases = [\n",
    "    'any_trial',\n",
    "]\n",
    "\n",
    "# Groups as a list of lists\n",
    "groups = None\n",
    "\n",
    "# right_handed = [281]\n",
    "# groups = [[280, 282, 299, 300, 301],\\\n",
    "#     [284, 285, 296, 297, 306, 307]]\n",
    "# Window to exctract (in ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "ss = exp_cohort.sessions\n",
    "\n",
    "ss_ = [this_ss for this_ss in ss \n",
    "       if (this_ss.subject_ID in [313, 314, 315, 316, 317, 318])\n",
    "       # if (this_ss.subject_ID in [ 314, 316])\n",
    "    and (this_ss.experiment_name == 'reaching_go_spout_bar_nov22')\n",
    "    and (this_ss.datetime.date() == datetime.date(2022,12,1))]\n",
    "\n",
    "exp_cohort.sessions = ss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([s.subject_ID for s in ss_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ss_[0].datetime.date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_cohort.sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cohort.sessions[0].df_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLOW 3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Process the whole experimental folder by trials\n",
    "\n",
    "exp_cohort.process_exp_by_trial(\n",
    "    trial_window, timelim, tasksfile, blank_spurious_event='spout', blank_timelim=[0, 65])\n",
    "    # this should use extract_data_from_session and prepare df_conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find if there is a matching photometry file and if it can be used:\n",
    "# rsync synchronization pulses matching between behaviour and photometry\n",
    "\n",
    "# Find if there is a matching photometry file:\n",
    "exp_cohort.match_sessions_to_files(photometry_dir, ext='ppd')\n",
    "\n",
    "# rsync synchronization pulses matching between behaviour and photometry\n",
    "exp_cohort.sync_photometry_files(2)\n",
    "\n",
    "# Find matching videos\n",
    "exp_cohort.match_sessions_to_files(video_dir, ext='mp4')\n",
    "\n",
    "# FInd matching DeepLabCut outputs files\n",
    "exp_cohort.match_sessions_to_files(video_dir, ext='h5', verbose=True)\n",
    "\n",
    "\n",
    "# exp_cohort.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([s.subject_ID for s in exp_cohort.sessions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cohort.sessions[0].times.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session plot \n",
    "\n",
    "I realised that this plot can never tell if a water drop was triggered by bar_off or spout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cohort.sessions[0].print_lines[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "re.match('abc ','abc de')\n",
    "\n",
    "expr = '^\\d+(?= ' + '.?Timestamp' + ')'\n",
    "a = [re.match(expr, L) for L in exp_cohort.sessions[0].print_lines if re.match(expr , L) is not None]\n",
    "int(a[0].group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ss in exp_cohort.sessions:\n",
    "    smrxname = re.sub('\\.txt', f'_{ss.task_name}.smrx', ss.file_name)\n",
    "    print(smrxname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\n",
    "        'button_press', 'bar', 'bar_off', 'spout', 'US_delay_timer', 'CS_offset_timer']\n",
    "state_def = [{'name': 'hold_for_water', 'onset': 'hold_for_water', 'offset': 'waiting_for_spout'},\n",
    "                    {'name': 'waiting_for_spout', 'onset': 'waiting_for_spout',\n",
    "                    'offset': 'busy_win'},\n",
    "                    {'name': 'busy_win', 'onset': 'busy_win',\n",
    "                        'offset': 'break_after_water'},\n",
    "                    {'name': 'break_after_water', 'onset': 'break_after_water',    'offset': 'waiting_for_bar'},\n",
    "                    {'name': 'break_after_no_water',       'onset': 'break_after_no_water', 'offset': 'waiting_for_bar'}]\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for ss in exp_cohort.sessions:\n",
    "\n",
    "    file_name = os.path.split(ss.file_name)\n",
    "    file_name_ = re.sub('\\.txt',  f'_{ss.task_name}.smrx', file_name[1])\n",
    "    smrxname = os.path.join(smrx_folder_path, file_name_)\n",
    "    print(smrxname)\n",
    "\n",
    "\n",
    "    bw = ss.times['busy_win']\n",
    "    sp = ss.times['spout']\n",
    "\n",
    "    x_spout = [this_bw for this_bw in bw for spouts in sp if (\n",
    "        spouts < this_bw) and (this_bw - spouts < 100)]\n",
    "\n",
    "    x_bar = [this_bw for this_bw in bw if not any(\n",
    "        [(spouts < this_bw) and (this_bw - spouts < 100) for spouts in sp])]\n",
    "        \n",
    "    event_ms = [{\n",
    "        'name': 'triggered by spout',\n",
    "        'time_ms': x_spout\n",
    "    },\n",
    "        {\n",
    "            'name': 'triggered by bar_off',\n",
    "            'time_ms': x_bar\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    if re.search('11\\-23',ss.file_name): #adapt to a bug \n",
    "        state_def[-1]['offset'] = 'wating_for_bar'\n",
    "    else:\n",
    "        state_def[-1]['offset'] = 'waiting_for_bar'\n",
    "\n",
    "\n",
    "    ss.plot_session(\n",
    "        keys, state_def, export_smrx=True, event_ms=event_ms, srmx_filename= smrxname)\n",
    "\n",
    "    summary_df = summary_df.append({\n",
    "        'file':ss.file_name,\n",
    "        'task':ss.task_name,\n",
    "        'triggered_by_spout': len(x_spout),\n",
    "        'triggered_by_bar_off': len(x_bar),\n",
    "        'reaching_trials': len(bw),\n",
    "        'trials': len(ss.times['hold_for_water'])},\n",
    "        ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trouble shooting for 314\n",
    "\n",
    "error is in event channel\n",
    "\n",
    "which channel?\n",
    "ReadEvents seems working for the first 10 divides at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\n",
    "        'button_press', 'bar', 'bar_off', 'spout', 'US_delay_timer', 'CS_offset_timer']\n",
    "state_def = [{'name': 'hold_for_water', 'onset': 'hold_for_water', 'offset': 'waiting_for_spout'},\n",
    "                    {'name': 'waiting_for_spout', 'onset': 'waiting_for_spout',\n",
    "                    'offset': 'busy_win'},\n",
    "                    {'name': 'busy_win', 'onset': 'busy_win',\n",
    "                        'offset': 'break_after_water'},\n",
    "                    {'name': 'break_after_water', 'onset': 'break_after_water',    'offset': 'waiting_for_bar'},\n",
    "                    {'name': 'break_after_no_water',       'onset': 'break_after_no_water', 'offset': 'waiting_for_bar'}]\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for ss in [exp_cohort.sessions[0]]:\n",
    "    smrxname = re.sub('\\.txt', f'_{ss.task_name}.smrx', ss.file_name)\n",
    "    print(smrxname)\n",
    "\n",
    "\n",
    "    bw = ss.times['busy_win']\n",
    "    sp = ss.times['spout']\n",
    "\n",
    "    x_spout = [this_bw for this_bw in bw for spouts in sp if (\n",
    "        spouts < this_bw) and (this_bw - spouts < 100)]\n",
    "\n",
    "    x_bar = [this_bw for this_bw in bw if not any(\n",
    "        [(spouts < this_bw) and (this_bw - spouts < 100) for spouts in sp])]\n",
    "        \n",
    "    event_ms = [{\n",
    "        'name': 'triggered by spout',\n",
    "        'time_ms': x_spout\n",
    "    },\n",
    "        {\n",
    "            'name': 'triggered by bar_off',\n",
    "            'time_ms': x_bar\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    if re.search('11\\-23',ss.file_name): #adapt to a bug \n",
    "        state_def[-1]['offset'] = 'wating_for_bar'\n",
    "    else:\n",
    "        state_def[-1]['offset'] = 'waiting_for_bar'\n",
    "\n",
    "\n",
    "    ss.plot_session(\n",
    "        keys, state_def, export_smrx=True, event_ms=event_ms, srmx_filename= smrxname, verbose=True)\n",
    "\n",
    "    summary_df = summary_df.append({\n",
    "        'file':ss.file_name,\n",
    "        'task':ss.task_name,\n",
    "        'triggered_by_spout': len(x_spout),\n",
    "        'triggered_by_bar_off': len(x_bar),\n",
    "        'reaching_trials': len(bw),\n",
    "        'trials': len(ss.times['hold_for_water'])},\n",
    "        ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('trialexp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d1e031f6f376662b97d9f481efb02d044bc4a5d17f5aae0c7d7abfcc2e5ac1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
